import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader, random_split
from torchvision import models
import os
from tqdm import tqdm  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º tqdm
import time

PAUSE_TIME = 30
CHECKPOINT_PATH = "checkpoint.pth"


# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
DATASET_PATH = "../data"
BATCH_SIZE = 8
IMG_SIZE = 96
EPOCHS = 10

# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
full_dataset = datasets.ImageFolder(root=DATASET_PATH, transform=transform)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É
train_size = int(0.8 * len(full_dataset))  # 80% –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
val_size = len(full_dataset) - train_size  # –û—Å—Ç–∞–ª—å–Ω—ã–µ 20% –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
num_classes = len(full_dataset.classes)
print(f"üü¢ –ù–∞–π–¥–µ–Ω–æ {num_classes} –∫–ª–∞—Å—Å–æ–≤: {full_dataset.classes}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é ResNet-18
model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(model.fc.in_features, num_classes)  # –ó–∞–º–µ–Ω—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
model = model.to(device)

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
best_accuracy = 0.0  # –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
patience = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π
epochs_no_improve = 0  # –°—á—ë—Ç—á–∏–∫ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è

for epoch in range(EPOCHS):
    # –û–±—É—á–µ–Ω–∏–µ
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0

    for images, labels in tqdm(train_loader, desc=f"–≠–ø–æ—Ö–∞ {epoch + 1}/{EPOCHS}", ncols=100):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    train_accuracy = 100 * correct / total
    print(f"üìå –≠–ø–æ—Ö–∞ {epoch + 1}/{EPOCHS} - –ü–æ—Ç–µ—Ä–∏: {train_loss / len(train_loader):.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {train_accuracy:.2f}%")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    val_accuracy = 100 * correct / total
    print(f"üìå –≠–ø–æ—Ö–∞ {epoch + 1}/{EPOCHS} - –í–∞–ª–∏–¥–∞—Ü–∏—è - –ü–æ—Ç–µ—Ä–∏: {val_loss / len(val_loader):.4f}, –¢–æ—á–Ω–æ—Å—Ç—å: {val_accuracy:.2f}%")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': train_loss,
    }, CHECKPOINT_PATH)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–∞–ª–∞ –ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å –ª—É—á—à–µ
    if val_accuracy > best_accuracy:
        best_accuracy = val_accuracy
        torch.save(model.state_dict(), "best_model.pth")  # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        print("‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1
        print(f"‚ö†Ô∏è –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π ({epochs_no_improve}/{patience})")

    # –ï—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π 3 —ç–ø–æ—Ö–∏ –ø–æ–¥—Ä—è–¥ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    if epochs_no_improve >= patience:
        print("üõë –†–∞–Ω–Ω–µ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è (Early Stopping)")
        break

    print(f"‚è∏Ô∏è –ü–µ—Ä–µ—Ä—ã–≤ {PAUSE_TIME//60} –º–∏–Ω—É—Ç –¥–ª—è –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è GPU...")
    time.sleep(PAUSE_TIME)


# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
torch.save(model.state_dict(), "emotion_model.pth")
print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
